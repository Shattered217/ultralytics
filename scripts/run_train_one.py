"""
ä¸¥æ ¼å¯è¿½è¸ªçš„è®­ç»ƒè¿è¡Œå™¨ (Traceable Training Runner)

ä¸ºå•ä¸ªå®éªŒè¿è¡Œä¸€æ¬¡è®­ç»ƒï¼Œè®°å½•å®Œæ•´çš„å®éªŒå¿«ç…§ï¼Œç¡®ä¿å¯å¤ç°æ€§ã€‚

ç”¨æ³•ï¼š
    python scripts/run_train_one.py --exp_name baseline --model_yaml ultralytics/cfg/models/v8/yolov8n_baseline.yaml --seed 0
    python scripts/run_train_one.py --exp_name ghost --model_yaml ultralytics/cfg/models/v8/yolov8n_ghost.yaml --seed 0 --data datasets/selfparts/data.yaml
"""

import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

import argparse
import json
import shutil
from datetime import datetime
from ultralytics import YOLO

from scripts.set_determinism import set_seed
from scripts.load_config import load_config, save_config
from scripts.record_env import record_environment


def create_experiment_snapshot(snapshot_dir, model_yaml, train_config, env_json_path):
    """åˆ›å»ºå®éªŒå¿«ç…§ï¼Œä¿å­˜æ‰€æœ‰é…ç½®æ–‡ä»¶"""
    snapshot_dir = Path(snapshot_dir)
    snapshot_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"\n{'='*80}")
    print("åˆ›å»ºå®éªŒå¿«ç…§")
    print(f"{'='*80}")
    
    # 1. ä¿å­˜æ¨¡å‹é…ç½®å‰¯æœ¬
    model_yaml_path = Path(model_yaml)
    model_copy = snapshot_dir / "model_config.yaml"
    shutil.copy2(model_yaml_path, model_copy)
    try:
        rel_path = model_copy.relative_to(Path.cwd())
    except ValueError:
        rel_path = model_copy
    print(f"âœ“ æ¨¡å‹é…ç½®å·²ä¿å­˜: {rel_path}")
    
    # 2. ä¿å­˜å®é™…ç”Ÿæ•ˆçš„è®­ç»ƒé…ç½®
    train_config_resolved = snapshot_dir / "resolved_train.yaml"
    save_config(train_config, train_config_resolved)
    try:
        rel_path = train_config_resolved.relative_to(Path.cwd())
    except ValueError:
        rel_path = train_config_resolved
    print(f"âœ“ è®­ç»ƒé…ç½®å·²ä¿å­˜: {rel_path}")
    
    # 3. ä¿å­˜æˆ–å¼•ç”¨ç¯å¢ƒä¿¡æ¯
    if env_json_path and Path(env_json_path).exists():
        env_copy = snapshot_dir / "env.json"
        shutil.copy2(env_json_path, env_copy)
        try:
            rel_path = env_copy.relative_to(Path.cwd())
        except ValueError:
            rel_path = env_copy
        print(f"âœ“ ç¯å¢ƒä¿¡æ¯å·²ä¿å­˜: {rel_path}")
    else:
        print(f"âš ï¸  ç¯å¢ƒä¿¡æ¯æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°†é‡æ–°è®°å½•")
        env_copy = snapshot_dir / "env.json"
        record_environment(str(env_copy))
        try:
            rel_path = env_copy.relative_to(Path.cwd())
        except ValueError:
            rel_path = env_copy
        print(f"âœ“ ç¯å¢ƒä¿¡æ¯å·²é‡æ–°è®°å½•: {rel_path}")
    
    # 4. ä¿å­˜å®éªŒå…ƒæ•°æ®
    metadata = {
        "exp_name": snapshot_dir.parent.parent.name,
        "seed": int(snapshot_dir.name.replace("seed", "")),
        "model_yaml": str(model_yaml),
        "snapshot_time": datetime.now().isoformat(),
        "snapshot_dir": str(snapshot_dir),
    }
    metadata_path = snapshot_dir / "metadata.json"
    with open(metadata_path, "w", encoding="utf-8") as f:
        json.dump(metadata, f, indent=2, ensure_ascii=False)
    try:
        rel_path = metadata_path.relative_to(Path.cwd())
    except ValueError:
        rel_path = metadata_path
    print(f"âœ“ å…ƒæ•°æ®å·²ä¿å­˜: {rel_path}")
    
    print(f"{'='*80}\n")
    
    return {
        "model_config": model_copy,
        "train_config": train_config_resolved,
        "env": env_copy,
        "metadata": metadata_path,
    }


def extract_metrics(results, results_dir):
    """ä»è®­ç»ƒç»“æœä¸­æå–å…³é”®æŒ‡æ ‡"""
    metrics = {
        "extraction_time": datetime.now().isoformat(),
        "results_dir": str(results_dir),
    }
    
    # å°è¯•ä»ä¸åŒæ¥æºæå–æŒ‡æ ‡
    try:
        # ä» results.results_dict æå–ï¼ˆè®­ç»ƒç»“æŸæ—¶çš„æŒ‡æ ‡ï¼‰
        if hasattr(results, 'results_dict') and results.results_dict:
            metrics.update({
                "final_metrics": results.results_dict
            })
        
        # ä»éªŒè¯ç»“æœæå–
        if hasattr(results, 'maps') and results.maps is not None:
            # mAP æŒ‡æ ‡
            if hasattr(results.maps, '__iter__'):
                metrics["mAP50-95"] = float(results.maps[0]) if len(results.maps) > 0 else None
            else:
                metrics["mAP50-95"] = float(results.maps)
        
        # ä» results.box æå–ï¼ˆå¦‚æœæ˜¯æ£€æµ‹ä»»åŠ¡ï¼‰
        if hasattr(results, 'box'):
            box_metrics = {}
            if hasattr(results.box, 'map'):
                box_metrics["mAP50-95"] = float(results.box.map)
            if hasattr(results.box, 'map50'):
                box_metrics["mAP50"] = float(results.box.map50)
            if hasattr(results.box, 'map75'):
                box_metrics["mAP75"] = float(results.box.map75)
            if hasattr(results.box, 'mp'):
                box_metrics["precision"] = float(results.box.mp)
            if hasattr(results.box, 'mr'):
                box_metrics["recall"] = float(results.box.mr)
            
            if box_metrics:
                metrics["box"] = box_metrics
        
        # å°è¯•è¯»å– results.csvï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        results_csv = Path(results_dir) / "results.csv"
        if results_csv.exists():
            import pandas as pd
            df = pd.read_csv(results_csv)
            last_row = df.iloc[-1].to_dict()
            
            # æå–å…³é”®æŒ‡æ ‡
            key_metrics = {}
            metric_map = {
                "metrics/mAP50(B)": "mAP50",
                "metrics/mAP50-95(B)": "mAP50-95",
                "metrics/precision(B)": "precision",
                "metrics/recall(B)": "recall",
                "train/box_loss": "box_loss",
                "train/cls_loss": "cls_loss",
                "train/dfl_loss": "dfl_loss",
                "val/box_loss": "val_box_loss",
                "val/cls_loss": "val_cls_loss",
                "val/dfl_loss": "val_dfl_loss",
            }
            
            for csv_key, metric_key in metric_map.items():
                if csv_key in last_row:
                    key_metrics[metric_key] = float(last_row[csv_key])
            
            if key_metrics:
                metrics["from_csv"] = key_metrics
        
    except Exception as e:
        print(f"âš ï¸  æå–æŒ‡æ ‡æ—¶å‡ºç°éƒ¨åˆ†é”™è¯¯: {e}")
        metrics["extraction_error"] = str(e)
    
    return metrics


def save_model_weights(results_dir, snapshot_dir):
    """ä¿å­˜æˆ–é“¾æ¥æ¨¡å‹æƒé‡æ–‡ä»¶"""
    results_dir = Path(results_dir)
    snapshot_dir = Path(snapshot_dir)
    weights_dir = snapshot_dir / "weights"
    weights_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"\n{'='*80}")
    print("ä¿å­˜æ¨¡å‹æƒé‡")
    print(f"{'='*80}")
    
    # æŸ¥æ‰¾æƒé‡æ–‡ä»¶
    weights_source = results_dir / "weights"
    if not weights_source.exists():
        print(f"âš ï¸  æƒé‡ç›®å½•ä¸å­˜åœ¨: {weights_source}")
        return
    
    # å¤åˆ¶ best.pt å’Œ last.pt
    for weight_file in ["best.pt", "last.pt"]:
        source = weights_source / weight_file
        target = weights_dir / weight_file
        
        if source.exists():
            shutil.copy2(source, target)
            size_mb = source.stat().st_size / (1024 * 1024)
            try:
                rel_path = target.relative_to(Path.cwd())
            except ValueError:
                rel_path = target
            print(f"âœ“ {weight_file} å·²å¤åˆ¶: {rel_path} ({size_mb:.2f} MB)")
        else:
            print(f"âš ï¸  {weight_file} ä¸å­˜åœ¨")
    
    print(f"{'='*80}\n")


def run_training(exp_name, model_yaml, seed, train_cfg, **overrides):
    """è¿è¡Œä¸€æ¬¡è®­ç»ƒå®éªŒ"""
    
    print("\n" + "â•”" + "="*78 + "â•—")
    print("â•‘" + " "*25 + "è®­ç»ƒè¿è¡Œå™¨å¯åŠ¨" + " "*39 + "â•‘")
    print("â•š" + "="*78 + "â•\n")
    
    # 1. è®¾ç½®éšæœºç§å­
    print(f"{'='*80}")
    print(f"æ­¥éª¤ 1/6: è®¾ç½®éšæœºç§å­")
    print(f"{'='*80}")
    set_seed(seed)
    print(f"âœ“ éšæœºç§å­å·²è®¾ç½®: {seed}\n")
    
    # 2. åˆ›å»ºå¿«ç…§ç›®å½•
    snapshot_dir = Path("results/runs") / exp_name / f"seed{seed}"
    print(f"{'='*80}")
    print(f"æ­¥éª¤ 2/6: åˆ›å»ºå¿«ç…§ç›®å½•")
    print(f"{'='*80}")
    print(f"å¿«ç…§ç›®å½•: {snapshot_dir}")
    
    # å¦‚æœç›®å½•å·²å­˜åœ¨ï¼Œè¯¢é—®æ˜¯å¦è¦†ç›–
    if snapshot_dir.exists():
        print(f"âš ï¸  å¿«ç…§ç›®å½•å·²å­˜åœ¨: {snapshot_dir}")
        response = input("æ˜¯å¦è¦†ç›–ï¼Ÿ(y/N): ").strip().lower()
        if response != 'y':
            print("âŒ è®­ç»ƒå·²å–æ¶ˆ")
            return None
        shutil.rmtree(snapshot_dir)
        print("âœ“ å·²åˆ é™¤æ—§å¿«ç…§")
    
    snapshot_dir.mkdir(parents=True, exist_ok=True)
    print(f"âœ“ å¿«ç…§ç›®å½•å·²åˆ›å»º\n")
    
    # 3. åŠ è½½è®­ç»ƒé…ç½®
    print(f"{'='*80}")
    print(f"æ­¥éª¤ 3/6: åŠ è½½è®­ç»ƒé…ç½®")
    print(f"{'='*80}")
    train_config = load_config(train_cfg, validate=True)
    print(f"âœ“ åŸºç¡€é…ç½®å·²åŠ è½½: {train_cfg}")
    
    # åº”ç”¨è¦†ç›–å‚æ•°
    for key, value in overrides.items():
        if value is not None:
            train_config[key] = value
            print(f"  è¦†ç›–å‚æ•°: {key} = {value}")
    
    # è®¾ç½®å¿…éœ€å‚æ•°
    train_config['model'] = model_yaml
    train_config['name'] = f"{exp_name}_seed{seed}"
    train_config['project'] = str(Path('results') / 'train')
    train_config['seed'] = seed
    train_config['exist_ok'] = True  # å…è®¸è¦†ç›–
    
    print(f"âœ“ é…ç½®å‚æ•°å·²å‡†å¤‡å®Œæˆ")
    print(f"  - æ¨¡å‹: {model_yaml}")
    print(f"  - æ•°æ®é›†: {train_config.get('data', 'N/A')}")
    print(f"  - è½®æ•°: {train_config.get('epochs', 'N/A')}")
    print(f"  - æ‰¹æ¬¡: {train_config.get('batch', 'N/A')}")
    print(f"  - è®¾å¤‡: {train_config.get('device', 'N/A')}")
    print()
    
    # 4. åˆ›å»ºå®éªŒå¿«ç…§
    print(f"{'='*80}")
    print(f"æ­¥éª¤ 4/6: åˆ›å»ºå®éªŒå¿«ç…§")
    print(f"{'='*80}")
    env_json_path = "results/metadata/env.json"
    snapshot_files = create_experiment_snapshot(
        snapshot_dir, 
        model_yaml, 
        train_config,
        env_json_path
    )
    
    # 5. å¼€å§‹è®­ç»ƒ
    print(f"{'='*80}")
    print(f"æ­¥éª¤ 5/6: å¼€å§‹è®­ç»ƒ")
    print(f"{'='*80}")
    print(f"å®éªŒåç§°: {exp_name}")
    print(f"éšæœºç§å­: {seed}")
    print(f"æ¨¡å‹é…ç½®: {model_yaml}")
    print(f"è®­ç»ƒå¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"{'='*80}\n")
    
    try:
        # åŠ è½½æ¨¡å‹
        model = YOLO(model_yaml)
        print(f"âœ“ æ¨¡å‹å·²åŠ è½½")
        
        # å¼€å§‹è®­ç»ƒ
        results = model.train(**train_config)
        print(f"\nâœ“ è®­ç»ƒå®Œæˆ")
        
        # è·å–è®­ç»ƒç»“æœç›®å½•ï¼ˆUltralyticsä¼šè‡ªåŠ¨æ·»åŠ runs/detect/å‰ç¼€ï¼‰
        # project='results/train', name='baseline_seed0'
        # å®é™…è¾“å‡º: runs/detect/results/train/baseline_seed0
        # æ‰€ä»¥éœ€è¦æ‰‹åŠ¨æ„å»ºå®Œæ•´è·¯å¾„
        results_dir = Path('runs') / 'detect' / train_config['project'] / train_config['name']
        if not results_dir.exists():
            # å¤‡é€‰æ–¹æ¡ˆï¼šå°è¯•ç›´æ¥ä½¿ç”¨é…ç½®çš„è·¯å¾„
            results_dir = Path(train_config['project']) / train_config['name']
        print(f"âœ“ ç»“æœç›®å½•: {results_dir}")
        
    except Exception as e:
        print(f"\nâŒ è®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        
        # ä¿å­˜é”™è¯¯ä¿¡æ¯
        error_log = snapshot_dir / "error.log"
        with open(error_log, "w", encoding="utf-8") as f:
            f.write(f"è®­ç»ƒå¤±è´¥æ—¶é—´: {datetime.now().isoformat()}\n")
            f.write(f"é”™è¯¯ä¿¡æ¯: {str(e)}\n\n")
            f.write("è¯¦ç»†å †æ ˆ:\n")
            traceback.print_exc(file=f)
        print(f"âœ“ é”™è¯¯æ—¥å¿—å·²ä¿å­˜: {error_log}")
        return None
    
    # 6. æå–æŒ‡æ ‡å¹¶ä¿å­˜
    print(f"\n{'='*80}")
    print(f"æ­¥éª¤ 6/6: æå–å’Œä¿å­˜æŒ‡æ ‡")
    print(f"{'='*80}")
    
    # æå–æŒ‡æ ‡
    metrics = extract_metrics(results, results_dir)
    
    # ä¿å­˜æŒ‡æ ‡
    metrics_file = snapshot_dir / "metrics_train.json"
    with open(metrics_file, "w", encoding="utf-8") as f:
        json.dump(metrics, f, indent=2, ensure_ascii=False)
    try:
        rel_path = metrics_file.relative_to(Path.cwd())
    except ValueError:
        rel_path = metrics_file
    print(f"âœ“ è®­ç»ƒæŒ‡æ ‡å·²ä¿å­˜: {rel_path}")
    
    # æ‰“å°å…³é”®æŒ‡æ ‡
    if "from_csv" in metrics:
        csv_metrics = metrics["from_csv"]
        print(f"\nå…³é”®æŒ‡æ ‡:")
        if "mAP50" in csv_metrics:
            print(f"  mAP50: {csv_metrics['mAP50']:.4f}")
        if "mAP50-95" in csv_metrics:
            print(f"  mAP50-95: {csv_metrics['mAP50-95']:.4f}")
        if "precision" in csv_metrics:
            print(f"  Precision: {csv_metrics['precision']:.4f}")
        if "recall" in csv_metrics:
            print(f"  Recall: {csv_metrics['recall']:.4f}")
    
    # ä¿å­˜æ¨¡å‹æƒé‡
    save_model_weights(results_dir, snapshot_dir)
    
    # åˆ›å»ºç¬¦å·é“¾æ¥æˆ–è®°å½• Ultralytics è¾“å‡ºç›®å½•
    link_info = snapshot_dir / "ultralytics_output.txt"
    with open(link_info, "w", encoding="utf-8") as f:
        f.write(f"Ultralytics è®­ç»ƒè¾“å‡ºç›®å½•:\n{results_dir}\n\n")
        f.write(f"æƒé‡æ–‡ä»¶å·²å¤åˆ¶åˆ°:\n{snapshot_dir / 'weights'}\n")
    try:
        rel_path = link_info.relative_to(Path.cwd())
    except ValueError:
        rel_path = link_info
    print(f"âœ“ è¾“å‡ºç›®å½•ä¿¡æ¯å·²ä¿å­˜: {rel_path}")
    
    # æœ€ç»ˆæ€»ç»“
    print(f"\n{'='*80}")
    print("è®­ç»ƒå®Œæˆæ€»ç»“")
    print(f"{'='*80}")
    print(f"å®éªŒåç§°: {exp_name}")
    print(f"éšæœºç§å­: {seed}")
    try:
        snap_rel = snapshot_dir.relative_to(Path.cwd())
        res_rel = results_dir.relative_to(Path.cwd())
    except ValueError:
        snap_rel = snapshot_dir
        res_rel = results_dir
    print(f"å¿«ç…§ç›®å½•: {snap_rel}")
    print(f"è®­ç»ƒç»“æœ: {res_rel}")
    print(f"\nå¿«ç…§å†…å®¹:")
    print(f"  - æ¨¡å‹é…ç½®: model_config.yaml")
    print(f"  - è®­ç»ƒé…ç½®: resolved_train.yaml")
    print(f"  - ç¯å¢ƒä¿¡æ¯: env.json")
    print(f"  - å…ƒæ•°æ®: metadata.json")
    print(f"  - è®­ç»ƒæŒ‡æ ‡: metrics_train.json")
    print(f"  - æ¨¡å‹æƒé‡: weights/best.pt, weights/last.pt")
    print(f"{'='*80}\n")
    
    return {
        "snapshot_dir": snapshot_dir,
        "results_dir": results_dir,
        "metrics": metrics,
        "success": True,
    }


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="ä¸¥æ ¼å¯è¿½è¸ªçš„è®­ç»ƒè¿è¡Œå™¨",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # è®­ç»ƒ baseline æ¨¡å‹ (seed=0)
  python scripts/run_train_one.py \\
      --exp_name baseline \\
      --model_yaml ultralytics/cfg/models/v8/yolov8n_baseline.yaml \\
      --seed 0

  # è®­ç»ƒ ghost æ¨¡å‹ï¼Œä½¿ç”¨è‡ªå®šä¹‰æ•°æ®é›†
  python scripts/run_train_one.py \\
      --exp_name ghost \\
      --model_yaml ultralytics/cfg/models/v8/yolov8n_ghost.yaml \\
      --seed 0 \\
      --data datasets/selfparts/data.yaml

  # è®­ç»ƒ ECA æ¨¡å‹ï¼Œè¦†ç›–è®­ç»ƒå‚æ•°
  python scripts/run_train_one.py \\
      --exp_name eca \\
      --model_yaml ultralytics/cfg/models/v8/yolov8n_eca.yaml \\
      --seed 1 \\
      --epochs 50 \\
      --batch 16
        """
    )
    
    # å¿…éœ€å‚æ•°
    parser.add_argument("--exp_name", type=str, required=True,
                       help="å®éªŒåç§° (ä¾‹å¦‚: baseline, ghost, eca, p2)")
    parser.add_argument("--model_yaml", type=str, required=True,
                       help="æ¨¡å‹é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--seed", type=int, required=True,
                       help="éšæœºç§å­")
    
    # å¯é€‰å‚æ•°
    parser.add_argument("--train_cfg", type=str, default="experiments/base_train.yaml",
                       help="è®­ç»ƒé…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: experiments/base_train.yaml)")
    
    # è®­ç»ƒå‚æ•°è¦†ç›–
    parser.add_argument("--data", type=str, help="æ•°æ®é›†é…ç½®æ–‡ä»¶")
    parser.add_argument("--epochs", type=int, help="è®­ç»ƒè½®æ•°")
    parser.add_argument("--batch", type=int, help="æ‰¹æ¬¡å¤§å°")
    parser.add_argument("--imgsz", type=int, help="å›¾åƒå°ºå¯¸")
    parser.add_argument("--device", type=str, help="è®¾å¤‡ (0, 0,1, cpu)")
    parser.add_argument("--workers", type=int, help="æ•°æ®åŠ è½½çº¿ç¨‹æ•°")
    parser.add_argument("--optimizer", type=str, help="ä¼˜åŒ–å™¨ (SGD, Adam, AdamW)")
    parser.add_argument("--lr0", type=float, help="åˆå§‹å­¦ä¹ ç‡")
    
    args = parser.parse_args()
    
    # æ”¶é›†è¦†ç›–å‚æ•°
    overrides = {
        "data": args.data,
        "epochs": args.epochs,
        "batch": args.batch,
        "imgsz": args.imgsz,
        "device": args.device,
        "workers": args.workers,
        "optimizer": args.optimizer,
        "lr0": args.lr0,
    }
    
    # è¿è¡Œè®­ç»ƒ
    result = run_training(
        exp_name=args.exp_name,
        model_yaml=args.model_yaml,
        seed=args.seed,
        train_cfg=args.train_cfg,
        **overrides
    )
    
    if result and result["success"]:
        print("ğŸ‰ è®­ç»ƒè¿è¡Œå®Œæˆï¼Œæ‰€æœ‰å¿«ç…§å·²ä¿å­˜ï¼")
        return 0
    else:
        print("âŒ è®­ç»ƒè¿è¡Œå¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯æ—¥å¿—ã€‚")
        return 1


if __name__ == "__main__":
    sys.exit(main())
