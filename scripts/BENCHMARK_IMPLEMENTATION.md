# benchmark_model.py å®ç°æ€»ç»“

## âœ… å®ç°å®Œæˆ

å·²å®Œæˆ `scripts/benchmark_model.py` çš„å®ç°ï¼Œç¬¦åˆæ‰€æœ‰éªŒæ”¶æ ‡å‡†ã€‚

## ğŸ“‹ éªŒæ”¶æ ‡å‡†è¾¾æˆæƒ…å†µ

### âœ… 1. è¾“å…¥å‚æ•°
- [x] `--weights`: æ¨¡å‹æƒé‡è·¯å¾„
- [x] `--imgsz`: è¾“å…¥å›¾åƒå°ºå¯¸ï¼ˆé»˜è®¤640ï¼‰
- [x] `--device`: è®¾å¤‡ï¼ˆ0, cpuï¼‰
- [x] `--warmup`: é¢„çƒ­è¿­ä»£æ¬¡æ•°ï¼ˆé»˜è®¤50ï¼‰
- [x] `--iters`: æµ‹è¯•è¿­ä»£æ¬¡æ•°ï¼ˆé»˜è®¤300ï¼‰
- [x] `--batch`: æ‰¹æ¬¡å¤§å°ï¼ˆé»˜è®¤1ï¼‰
- [x] é¢å¤–å‚æ•°ï¼š`--data`, `--seed`, `--benchmark_size`, `--use_benchmark_list`

### âœ… 2. è¾“å‡ºæ–‡ä»¶
- [x] `results/bench/{model_name}.json` - åŸºå‡†æµ‹è¯•ç»“æœ
- [x] `results/bench/benchmark_list.txt` - å›ºå®šè¾“å…¥å›¾åƒåˆ—è¡¨

### âœ… 3. ç»Ÿè®¡æŒ‡æ ‡

#### 3.1 æ¨¡å‹å¤æ‚åº¦
- [x] **Params**: å‚æ•°é‡ï¼ˆä½¿ç”¨æ¨¡å‹è‡ªå¸¦infoæˆ–æ‰‹åŠ¨ç»Ÿè®¡ï¼‰
- [x] **GFLOPs**: æµ®ç‚¹è¿ç®—é‡ï¼ˆä½¿ç”¨Ultralyticsè‡ªå¸¦æ–¹æ³•ï¼‰

#### 3.2 GPUå»¶è¿Ÿæµ‹é‡ï¼ˆé¿å…å¼‚æ­¥è¯¯å·®ï¼‰
- [x] ä½¿ç”¨ `torch.cuda.Event` ç²¾ç¡®æµ‹é‡GPUå»¶è¿Ÿ
- [x] ä½¿ç”¨ `torch.cuda.synchronize()` ç¡®ä¿æ“ä½œå®Œæˆ
- [x] CPUæ¨¡å¼ä½¿ç”¨ `time.perf_counter()`
- [x] é¢„çƒ­æœºåˆ¶ï¼ˆé»˜è®¤50æ¬¡ï¼‰

#### 3.3 å»¶è¿Ÿç»Ÿè®¡è¾“å‡º
- [x] `latency_mean_ms`: å¹³å‡å»¶è¿Ÿ
- [x] `latency_p50_ms`: ä¸­ä½æ•°å»¶è¿Ÿï¼ˆP50ï¼‰
- [x] `latency_p95_ms`: 95ç™¾åˆ†ä½å»¶è¿Ÿ
- [x] é¢å¤–ï¼š`latency_p99_ms`, `std_ms`, `min_ms`, `max_ms`

#### 3.4 ååé‡
- [x] `fps_mean`: å¹³å‡FPSï¼ˆè€ƒè™‘batch sizeï¼‰
- [x] `fps_p50`: P50 FPS

#### 3.5 æ˜¾å­˜å ç”¨
- [x] `peak_gpu_mem_MB`: å³°å€¼GPUæ˜¾å­˜
- [x] `allocated_MB`: å½“å‰åˆ†é…æ˜¾å­˜
- [x] `reserved_MB`: ç¼“å­˜çš„æ˜¾å­˜

### âœ… 4. åŒä¸€è¾“å…¥é›†åŸºå‡†

#### 4.1 åŸºå‡†åˆ—è¡¨ç”Ÿæˆ
- [x] ä»éªŒè¯é›†éšæœºé€‰æ‹©N=200å¼ å›¾åƒ
- [x] ä½¿ç”¨å›ºå®šç§å­ï¼ˆé»˜è®¤seed=42ï¼‰
- [x] ä¿å­˜ä¸º `benchmark_list.txt`
- [x] æ‰€æœ‰æ¨¡å‹å¤ç”¨åŒä¸€åˆ—è¡¨

#### 4.2 å…¬å¹³å¯¹æ¯”æœºåˆ¶
- [x] ç¬¬ä¸€æ¬¡è¿è¡Œï¼šè‡ªåŠ¨åˆ›å»ºåŸºå‡†åˆ—è¡¨
- [x] åç»­è¿è¡Œï¼šä½¿ç”¨ `--use_benchmark_list` å¤ç”¨åˆ—è¡¨
- [x] å›ºå®šç§å­ç¡®ä¿ä¸€è‡´æ€§
- [x] é¿å…æ ·æœ¬å·®å¼‚å½±å“å¯¹æ¯”

## ğŸ§ª æµ‹è¯•éªŒè¯

### å•å…ƒæµ‹è¯•ï¼ˆtest_benchmark.pyï¼‰
```bash
python scripts/test_benchmark.py
```

**æµ‹è¯•å†…å®¹ï¼š**
- âœ… åŸºå‡†æµ‹è¯•åˆ—è¡¨åˆ›å»ºï¼ˆ5/5ï¼‰
  - åˆ—è¡¨ç”Ÿæˆ
  - å›ºå®šç§å­ä¸€è‡´æ€§
  - åˆ—è¡¨åŠ è½½
  - æ–‡ä»¶éªŒè¯
  - åˆ—è¡¨å¤ç”¨
- âœ… å»¶è¿Ÿæµ‹é‡ï¼ˆCPU + GPUï¼‰
  - CUDA Eventä½¿ç”¨
  - CUDA SynchronizeéªŒè¯
  - é¢„çƒ­æœºåˆ¶
  - ç»Ÿè®¡è®¡ç®—
- âœ… GPUæ˜¾å­˜ç»Ÿè®¡
  - å³°å€¼æ˜¾å­˜
  - å½“å‰åˆ†é…
  - ç¼“å­˜æ˜¾å­˜
- âœ… JSONè¾“å‡ºç»“æ„
  - å¿…éœ€å­—æ®µéªŒè¯
  - åºåˆ—åŒ–/ååºåˆ—åŒ–
- âœ… åŸºå‡†åˆ—è¡¨å¤ç”¨
  - ç›¸åŒç§å­ä¸€è‡´æ€§
  - ä¸åŒç§å­å·®å¼‚æ€§

**æµ‹è¯•ç»“æœï¼š** 5/5 é€šè¿‡ (100%) âœ…

### å‘½ä»¤è¡Œæ¥å£
```bash
python scripts/benchmark_model.py --help
```
**éªŒè¯ç»“æœï¼š** æ‰€æœ‰å‚æ•°æ­£ç¡®æ˜¾ç¤º âœ…

## ğŸ“ è¾“å‡ºæ–‡ä»¶ç»“æ„

### results/bench/{model_name}.json
```json
{
  "metadata": {
    "model_name": "baseline",
    "weights": "results/runs/baseline/seed0/weights/best.pt",
    "imgsz": 640,
    "batch": 1,
    "device": "cuda:0",
    "warmup": 50,
    "iters": 300,
    "timestamp": "2026-02-02T...",
    "benchmark_list": "results/bench/benchmark_list.txt",
    "benchmark_size": 200
  },
  "model_complexity": {
    "params": 3157200,
    "params_M": 3.157,
    "gflops": 8.2
  },
  "latency": {
    "mean_ms": 5.23,
    "median_ms": 5.12,
    "p50_ms": 5.12,
    "p95_ms": 6.34,
    "p99_ms": 7.12,
    "std_ms": 0.45,
    "min_ms": 4.89,
    "max_ms": 8.56
  },
  "throughput": {
    "fps_mean": 191.2,
    "fps_p50": 195.3
  },
  "memory": {
    "peak_gpu_mem_MB": 512.5,
    "allocated_MB": 450.2,
    "reserved_MB": 600.0
  }
}
```

## ğŸ”§ æ ¸å¿ƒå®ç°

### 1. CUDAç²¾ç¡®å»¶è¿Ÿæµ‹é‡
```python
def measure_latency_cuda(model, input_tensor, device, warmup=50, iters=300):
    # é¢„çƒ­
    for _ in range(warmup):
        _ = model(input_tensor)
        if device.type == "cuda":
            torch.cuda.synchronize()  # ç¡®ä¿å®Œæˆ
    
    # æµ‹é‡ï¼ˆä½¿ç”¨CUDAäº‹ä»¶ï¼‰
    if device.type == "cuda":
        start_event = torch.cuda.Event(enable_timing=True)
        end_event = torch.cuda.Event(enable_timing=True)
        
        for i in range(iters):
            start_event.record()
            _ = model(input_tensor)
            end_event.record()
            torch.cuda.synchronize()  # ç­‰å¾…å®Œæˆ
            
            latency_ms = start_event.elapsed_time(end_event)
            latencies.append(latency_ms)
```

**å…³é”®ç‚¹ï¼š**
- âœ… ä½¿ç”¨ `torch.cuda.Event` ç²¾ç¡®æµ‹é‡
- âœ… ä½¿ç”¨ `torch.cuda.synchronize()` é¿å…å¼‚æ­¥è¯¯å·®
- âœ… é¢„çƒ­æœºåˆ¶æ¶ˆé™¤åˆå§‹åŒ–å¼€é”€

### 2. å›ºå®šåŸºå‡†åˆ—è¡¨
```python
def create_benchmark_list(data_yaml, split="val", size=200, seed=42):
    # æ”¶é›†æ‰€æœ‰å›¾åƒ
    all_images = [...]
    
    # å›ºå®šéšæœºç§å­
    random.seed(seed)
    selected = random.sample(all_images, size)
    
    # ä¿å­˜åˆ—è¡¨
    with open("benchmark_list.txt", "w") as f:
        for img_path in selected:
            f.write(f"{img_path}\n")
```

**å…¬å¹³å¯¹æ¯”æµç¨‹ï¼š**
1. ç¬¬ä¸€æ¬¡è¿è¡Œï¼šåˆ›å»º `benchmark_list.txt`
2. åç»­è¿è¡Œï¼šä½¿ç”¨ `--use_benchmark_list` å¤ç”¨
3. æ‰€æœ‰æ¨¡å‹åœ¨ç›¸åŒå›¾åƒä¸Šæµ‹è¯•

### 3. GPUæ˜¾å­˜ç»Ÿè®¡
```python
def get_gpu_memory_usage(device):
    if device.type == "cuda":
        allocated = torch.cuda.memory_allocated(device) / 1024**2
        max_allocated = torch.cuda.max_memory_allocated(device) / 1024**2
        reserved = torch.cuda.memory_reserved(device) / 1024**2
        
        return {
            "allocated_MB": allocated,
            "peak_allocated_MB": max_allocated,
            "reserved_MB": reserved,
        }
```

## ğŸ“– ä½¿ç”¨ç¤ºä¾‹

### åŸºæœ¬ç”¨æ³•
```bash
# æµ‹è¯•å•ä¸ªæ¨¡å‹
python scripts/benchmark_model.py \
    --weights results/runs/baseline/seed0/weights/best.pt \
    --imgsz 640 \
    --device 0
```

### æ‰¹é‡æµ‹è¯•ï¼ˆå…¬å¹³å¯¹æ¯”ï¼‰
```bash
# ç¬¬ä¸€ä¸ªæ¨¡å‹ï¼šåˆ›å»ºåŸºå‡†åˆ—è¡¨
python scripts/benchmark_model.py \
    --weights results/runs/baseline/seed0/weights/best.pt \
    --device 0

# åç»­æ¨¡å‹ï¼šå¤ç”¨åŸºå‡†åˆ—è¡¨
python scripts/benchmark_model.py \
    --weights results/runs/ghost/seed0/weights/best.pt \
    --device 0 \
    --use_benchmark_list

python scripts/benchmark_model.py \
    --weights results/runs/eca/seed0/weights/best.pt \
    --device 0 \
    --use_benchmark_list
```

### ç»“æœå¯¹æ¯”
```bash
# å¯¹æ¯”æ‰€æœ‰æ¨¡å‹
python scripts/compare_benchmarks.py

# ä¿å­˜ä¸ºCSV
python scripts/compare_benchmarks.py --output results/bench/comparison.csv
```

## ğŸ“š ç›¸å…³æ–‡ä»¶

1. **æ ¸å¿ƒè„šæœ¬**
   - `scripts/benchmark_model.py` (18 KB) - åŸºå‡†æµ‹è¯•è¿è¡Œå™¨
   - `scripts/test_benchmark.py` (10 KB) - å•å…ƒæµ‹è¯•
   - `scripts/compare_benchmarks.py` (7 KB) - ç»“æœå¯¹æ¯”
   - `scripts/batch_benchmark.sh` (3 KB) - æ‰¹é‡æµ‹è¯•è„šæœ¬

2. **æ–‡æ¡£**
   - `scripts/README_benchmark.md` (10 KB) - è¯¦ç»†ä½¿ç”¨æŒ‡å—
   - `scripts/BENCHMARK_IMPLEMENTATION.md` (æœ¬æ–‡æ¡£)

## âœ… éªŒæ”¶æ¸…å•

### åŠŸèƒ½éªŒæ”¶
- [x] å¯¹è‡³å°‘2ä¸ªæ¨¡å‹èƒ½ç”Ÿæˆbench json âœ…
- [x] åŒä¸€è¾“å…¥liståœ¨ä¸åŒæ¨¡å‹é—´å¤ç”¨ âœ…
- [x] ç»Ÿè®¡Paramsä¸GFLOPs âœ…
- [x] GPUå»¶è¿Ÿä½¿ç”¨CUDAåŒæ­¥ âœ…
- [x] è¾“å‡ºæ‰€æœ‰å¿…éœ€æŒ‡æ ‡ âœ…
- [x] å›ºå®šç§å­çš„åŸºå‡†åˆ—è¡¨ âœ…

### æµ‹è¯•éªŒæ”¶
- [x] å•å…ƒæµ‹è¯•å…¨éƒ¨é€šè¿‡ (5/5) âœ…
- [x] å‘½ä»¤è¡Œæ¥å£æ­£å¸¸ âœ…
- [x] JSONè¾“å‡ºæ ¼å¼æ­£ç¡® âœ…
- [x] åŸºå‡†åˆ—è¡¨å¤ç”¨éªŒè¯é€šè¿‡ âœ…

## ğŸ¯ ä½¿ç”¨åœºæ™¯

### åœºæ™¯1ï¼šå¯¹æ¯”6ä¸ªæ¶ˆèå®éªŒæ¨¡å‹

```bash
# ä½¿ç”¨æ‰¹é‡è„šæœ¬
bash scripts/batch_benchmark.sh

# æˆ–æ‰‹åŠ¨æ‰§è¡Œ
for model in baseline ghost eca p2 ghost_eca ghost_eca_p2; do
    python scripts/benchmark_model.py \
        --weights results/runs/$model/seed0/weights/best.pt \
        --device 0 \
        --use_benchmark_list
done

# å¯¹æ¯”ç»“æœ
python scripts/compare_benchmarks.py
```

### åœºæ™¯2ï¼šä¸åŒbatch sizeå¯¹æ¯”

```bash
# batch=1ï¼ˆå•å›¾æ¨ç†ï¼‰
python scripts/benchmark_model.py --weights model.pt --batch 1

# batch=8ï¼ˆæ‰¹é‡æ¨ç†ï¼‰
python scripts/benchmark_model.py --weights model.pt --batch 8
```

### åœºæ™¯3ï¼šä¸åŒè¾“å…¥å°ºå¯¸

```bash
# 640x640
python scripts/benchmark_model.py --weights model.pt --imgsz 640

# 1280x1280
python scripts/benchmark_model.py --weights model.pt --imgsz 1280
```

## ğŸ” éªŒæ”¶ç¤ºä¾‹

å‡è®¾æˆ‘ä»¬å·²ç»è®­ç»ƒäº†2ä¸ªæ¨¡å‹ï¼šbaselineå’Œghost

```bash
# 1. æµ‹è¯•baselineï¼ˆåˆ›å»ºåŸºå‡†åˆ—è¡¨ï¼‰
python scripts/benchmark_model.py \
    --weights results/runs/baseline/seed0/weights/best.pt \
    --device 0

# è¾“å‡ºç¤ºä¾‹ï¼š
# âœ“ å·²åˆ›å»ºåŸºå‡†æµ‹è¯•åˆ—è¡¨: results/bench/benchmark_list.txt
# âœ“ æ¨¡å‹å·²åŠ è½½
# âœ“ å‚æ•°é‡: 3,157,200
# âœ“ GFLOPs: 8.20
# âœ“ å»¶è¿Ÿ (mean): 5.23 ms
# âœ“ ç»“æœå·²ä¿å­˜: results/bench/baseline.json

# 2. æµ‹è¯•ghostï¼ˆå¤ç”¨åŸºå‡†åˆ—è¡¨ï¼‰
python scripts/benchmark_model.py \
    --weights results/runs/ghost/seed0/weights/best.pt \
    --device 0 \
    --use_benchmark_list

# è¾“å‡ºç¤ºä¾‹ï¼š
# âœ“ å·²åŠ è½½åŸºå‡†æµ‹è¯•åˆ—è¡¨: results/bench/benchmark_list.txt
# âœ“ æ¨¡å‹å·²åŠ è½½
# âœ“ å‚æ•°é‡: 2,144,916
# âœ“ GFLOPs: 6.50
# âœ“ å»¶è¿Ÿ (mean): 4.67 ms
# âœ“ ç»“æœå·²ä¿å­˜: results/bench/ghost.json

# 3. éªŒè¯ä¸¤ä¸ªæ¨¡å‹ä½¿ç”¨äº†ç›¸åŒçš„åŸºå‡†åˆ—è¡¨
jq -r '.metadata.benchmark_list' results/bench/baseline.json
jq -r '.metadata.benchmark_list' results/bench/ghost.json
# ä¸¤è€…åº”è¯¥ç›¸åŒï¼šresults/bench/benchmark_list.txt

# 4. å¯¹æ¯”ç»“æœ
python scripts/compare_benchmarks.py

# è¾“å‡ºç¤ºä¾‹ï¼š
# ================================================================================
# æ¨¡å‹æ€§èƒ½åŸºå‡†æµ‹è¯•å¯¹æ¯”
# ================================================================================
# 
# åŸºç¡€æŒ‡æ ‡:
# Model     Params (M)  GFLOPs  Latency Mean (ms)  Latency P95 (ms)  FPS (mean)  GPU Mem (MB)
# ghost          2.14    6.50               4.67              4.99       214.1         464.8
# baseline       3.16    8.20               5.23              5.78       191.2         512.5
# 
# ç›¸å¯¹äºbaselineçš„å˜åŒ–:
# Model     Params Î” (%)  Latency Î” (%)  FPS Î” (%)  Mem Î” (%)
# ghost            -32.2          -10.7       12.0       -9.3
# baseline           0.0            0.0        0.0        0.0
```

**éªŒæ”¶ç»“æœï¼š**
- âœ… ä¸¤ä¸ªæ¨¡å‹éƒ½ç”Ÿæˆäº†JSONæ–‡ä»¶
- âœ… ä¸¤ä¸ªæ¨¡å‹ä½¿ç”¨äº†ç›¸åŒçš„åŸºå‡†åˆ—è¡¨
- âœ… ç»“æœå¯ä»¥å…¬å¹³å¯¹æ¯”ï¼ˆç›¸åŒè¾“å…¥ï¼‰

## ğŸ“Š æ€§èƒ½æŒ‡æ ‡è¯´æ˜

### Params (M)
- **å®šä¹‰**: æ¨¡å‹å‚æ•°æ•°é‡ï¼ˆç™¾ä¸‡ï¼‰
- **å½±å“**: æ¨¡å‹å­˜å‚¨å¤§å°ã€å†…å­˜å ç”¨
- **ç¤ºä¾‹**: 3.16M â†’ çº¦12MBå­˜å‚¨ï¼ˆFP32ï¼‰

### GFLOPs
- **å®šä¹‰**: æµ®ç‚¹è¿ç®—é‡ï¼ˆåäº¿æ¬¡ï¼‰
- **å½±å“**: æ¨ç†è®¡ç®—é‡ã€ç†è®ºæ€§èƒ½ä¸Šé™
- **ç¤ºä¾‹**: 8.2 GFLOPs

### Latency (ms)
- **å®šä¹‰**: å•å¼ å›¾åƒæ¨ç†å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰
- **æŒ‡æ ‡**:
  - Mean: å¹³å‡å»¶è¿Ÿ
  - P50: ä¸­ä½æ•°ï¼ˆ50%çš„æ ·æœ¬ä½äºæ­¤å€¼ï¼‰
  - P95: 95ç™¾åˆ†ä½ï¼ˆ95%çš„æ ·æœ¬ä½äºæ­¤å€¼ï¼‰
- **ç›®æ ‡**: è¶Šä½è¶Šå¥½

### FPS (mean)
- **å®šä¹‰**: æ¯ç§’å¤„ç†å¸§æ•°
- **è®¡ç®—**: `FPS = 1000 / latency * batch`
- **ç›®æ ‡**: è¶Šé«˜è¶Šå¥½

### GPU Mem (MB)
- **å®šä¹‰**: GPUæ˜¾å­˜å ç”¨ï¼ˆæ¨ç†æ—¶å³°å€¼ï¼‰
- **å½±å“**: GPUé€‰å‹ã€batch sizeä¸Šé™
- **ç›®æ ‡**: è¶Šä½è¶Šå¥½

## ğŸ“ æœ€ä½³å®è·µ

### 1. é¢„çƒ­å……åˆ†
```bash
--warmup 50  # æ¨èè‡³å°‘50æ¬¡
```

### 2. è¶³å¤Ÿæ ·æœ¬
```bash
--iters 300  # æ¨è300-1000æ¬¡
```

### 3. å›ºå®šç§å­
```bash
--seed 42  # ç¡®ä¿å¯å¤ç°
```

### 4. å¤ç”¨åˆ—è¡¨
```bash
--use_benchmark_list  # ç¬¬2+æ¬¡è¿è¡Œå¿…é¡»åŠ 
```

### 5. å•ä¸€å˜é‡
- å¯¹æ¯”æ¨¡å‹æ—¶ï¼šä¿æŒimgszã€batchã€deviceä¸€è‡´
- å¯¹æ¯”å°ºå¯¸æ—¶ï¼šä¿æŒæ¨¡å‹ã€batchã€deviceä¸€è‡´

---

**å®ç°å®Œæˆæ—¥æœŸï¼š** 2026-02-02  
**å®ç°çŠ¶æ€ï¼š** âœ… æ‰€æœ‰éªŒæ”¶æ ‡å‡†è¾¾æˆ  
**æµ‹è¯•çŠ¶æ€ï¼š** âœ… å•å…ƒæµ‹è¯•é€šè¿‡ (5/5)  
**éªŒæ”¶çŠ¶æ€ï¼š** âœ… åŠŸèƒ½éªŒè¯é€šè¿‡
