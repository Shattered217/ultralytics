# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license
"""
é¢å¤–çš„è‡ªå®šä¹‰æ¨¡å—ï¼šSPDConv å’Œ EMA
ç”¨äºå°ç›®æ ‡æ£€æµ‹çš„åˆ›æ–°ç®—å­
"""

import torch
import torch.nn as nn
import torch.nn.functional as F

__all__ = ("SPDConv", "EMA", "BiFPN_Add2", "BiFPN_Add3", "GSConv", "VoVGSCSP", "DySample_Simple", "GSBottleneck")


class SPDConv(nn.Module):
    """
    SPD-Conv: Space-to-Depth Convolution
    å®ç°ç©ºé—´è½¬æ·±åº¦çš„æ— æŸä¸‹é‡‡æ ·ï¼Œå°† 2x2 ç©ºé—´åŒºåŸŸè½¬æ¢ä¸º 4 å€æ·±åº¦é€šé“ã€‚
    
    é€‚ç”¨äºå°ç›®æ ‡æ£€æµ‹ï¼Œé¿å…ä¼ ç»Ÿä¸‹é‡‡æ ·å¯¼è‡´çš„ä¿¡æ¯ä¸¢å¤±ã€‚
    
    Args:
        in_channels (int): è¾“å…¥é€šé“æ•°
        out_channels (int): è¾“å‡ºé€šé“æ•°
        kernel_size (int): å·ç§¯æ ¸å¤§å°ï¼Œé»˜è®¤ 3
        stride (int): æ­¥é•¿ï¼Œé»˜è®¤ 1
        padding (int): å¡«å……ï¼Œé»˜è®¤ 1
        
    Examples:
        >>> import torch
        >>> m = SPDConv(64, 128)
        >>> x = torch.randn(1, 64, 64, 64)
        >>> y = m(x)
        >>> print(y.shape)  # torch.Size([1, 128, 32, 32])
    """
    
    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):
        super().__init__()
        self.conv = nn.Conv2d(
            in_channels * 4,  # SPD åé€šé“æ•°å˜ä¸º 4 å€
            out_channels,
            kernel_size=kernel_size,
            stride=stride,
            padding=padding,
            bias=False
        )
        self.bn = nn.BatchNorm2d(out_channels)
        self.act = nn.SiLU(inplace=True)
    
    def forward(self, x):
        """
        å‰å‘ä¼ æ’­ï¼šæ‰§è¡Œç©ºé—´åˆ°æ·±åº¦çš„è½¬æ¢ï¼Œç„¶åè¿›è¡Œå·ç§¯ã€‚
        
        Args:
            x (torch.Tensor): å½¢çŠ¶ä¸º (B, C, H, W) çš„è¾“å…¥å¼ é‡
            
        Returns:
            (torch.Tensor): å½¢çŠ¶ä¸º (B, out_channels, H//2, W//2) çš„è¾“å‡ºå¼ é‡
        """
        # Space-to-Depth: (B, C, H, W) -> (B, 4C, H/2, W/2)
        x = self.space_to_depth(x)
        x = self.conv(x)
        x = self.bn(x)
        x = self.act(x)
        return x
    
    @staticmethod
    def space_to_depth(x, block_size=2):
        """
        å°†ç©ºé—´ç»´åº¦è½¬æ¢ä¸ºæ·±åº¦ç»´åº¦ã€‚
        
        Args:
            x (torch.Tensor): è¾“å…¥å¼ é‡ï¼Œå½¢çŠ¶ (B, C, H, W)
            block_size (int): å—å¤§å°ï¼Œé»˜è®¤ 2
            
        Returns:
            (torch.Tensor): å½¢çŠ¶ä¸º (B, C*block_size^2, H//block_size, W//block_size)
        """
        B, C, H, W = x.shape
        # ç¡®ä¿å°ºå¯¸å¯è¢« block_size æ•´é™¤
        assert H % block_size == 0 and W % block_size == 0, \
            f"Height ({H}) and Width ({W}) must be divisible by block_size ({block_size})"
        
        # é‡å¡‘å¹¶é‡æ–°æ’åˆ—
        x = x.view(B, C, H // block_size, block_size, W // block_size, block_size)
        x = x.permute(0, 1, 3, 5, 2, 4).contiguous()
        x = x.view(B, C * (block_size ** 2), H // block_size, W // block_size)
        return x


class EMA(nn.Module):
    """
    EMA: Efficient Multi-Scale Attention
    å®ç°è½»é‡åŒ–çš„è·¨ç©ºé—´ç»´åº¦æ³¨æ„åŠ›æœºåˆ¶ï¼Œç”¨äºå¢å¼ºç‰¹å¾è¡¨è¾¾èƒ½åŠ›ã€‚
    
    é€šè¿‡åˆ†ç»„å·ç§¯å’Œå¤šå°ºåº¦æ± åŒ–å®ç°é«˜æ•ˆçš„æ³¨æ„åŠ›è®¡ç®—ã€‚
    
    Args:
        channels (int): è¾“å…¥/è¾“å‡ºé€šé“æ•°
        num_groups (int): åˆ†ç»„æ•°ï¼Œé»˜è®¤ 8
        spatial_kernel (int): ç©ºé—´æ³¨æ„åŠ›çš„å·ç§¯æ ¸å¤§å°ï¼Œé»˜è®¤ 7
        
    Examples:
        >>> import torch
        >>> m = EMA(256)
        >>> x = torch.randn(1, 256, 32, 32)
        >>> y = m(x)
        >>> print(y.shape)  # torch.Size([1, 256, 32, 32])
    """
    
    def __init__(self, channels, num_groups=8, spatial_kernel=7):
        super().__init__()
        self.channels = channels
        self.num_groups = num_groups
        assert channels % num_groups == 0, f"channels ({channels}) must be divisible by num_groups ({num_groups})"
        
        self.group_channels = channels // num_groups
        
        # 1x1 å·ç§¯ç”¨äºé€šé“æ³¨æ„åŠ›ï¼ˆä½¿ç”¨ GroupNorm é¿å…æ‰¹æ¬¡å¤§å°é™åˆ¶ï¼‰
        reduced_channels = max(channels // 4, 8)
        self.channel_attention = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Conv2d(channels, reduced_channels, 1, bias=False),
            nn.GroupNorm(num_groups=min(reduced_channels, 4), num_channels=reduced_channels),
            nn.SiLU(inplace=True),
            nn.Conv2d(reduced_channels, channels, 1, bias=False),
            nn.Sigmoid()
        )
        
        # åˆ†ç»„å·ç§¯ç”¨äºç©ºé—´æ³¨æ„åŠ›
        self.spatial_attention = nn.Sequential(
            nn.Conv2d(
                channels,
                channels,
                kernel_size=spatial_kernel,
                padding=spatial_kernel // 2,
                groups=num_groups,
                bias=False
            ),
            nn.GroupNorm(num_groups=num_groups, num_channels=channels),
            nn.Sigmoid()
        )
        
        # å¤šå°ºåº¦æ± åŒ–è·¯å¾„
        self.pool_sizes = [1, 3, 5]
        self.pool_convs = nn.ModuleList([
            nn.Sequential(
                nn.AvgPool2d(kernel_size=k, stride=1, padding=k // 2),
                nn.Conv2d(channels, channels, 1, bias=False),
                nn.GroupNorm(num_groups=num_groups, num_channels=channels)
            ) for k in self.pool_sizes
        ])
        
        # èåˆå±‚
        self.fusion = nn.Sequential(
            nn.Conv2d(channels * (len(self.pool_sizes) + 1), channels, 1, bias=False),
            nn.GroupNorm(num_groups=num_groups, num_channels=channels),
            nn.SiLU(inplace=True)
        )
    
    def forward(self, x):
        """
        å‰å‘ä¼ æ’­ï¼šè®¡ç®—å¤šå°ºåº¦æ³¨æ„åŠ›å¹¶åº”ç”¨åˆ°è¾“å…¥ç‰¹å¾ã€‚
        
        Args:
            x (torch.Tensor): å½¢çŠ¶ä¸º (B, C, H, W) çš„è¾“å…¥å¼ é‡
            
        Returns:
            (torch.Tensor): å½¢çŠ¶ä¸º (B, C, H, W) çš„è¾“å‡ºå¼ é‡
        """
        B, C, H, W = x.shape
        identity = x
        
        # é€šé“æ³¨æ„åŠ›
        ca = self.channel_attention(x)
        x_ca = x * ca
        
        # ç©ºé—´æ³¨æ„åŠ›
        sa = self.spatial_attention(x)
        x_sa = x * sa
        
        # å¤šå°ºåº¦æ± åŒ–
        pool_feats = [x_ca]
        for pool_conv in self.pool_convs:
            pool_feats.append(pool_conv(x_sa))
        
        # èåˆæ‰€æœ‰å°ºåº¦
        x_fused = torch.cat(pool_feats, dim=1)
        x_fused = self.fusion(x_fused)
        
        # æ®‹å·®è¿æ¥
        out = x_fused + identity
        return out


class BiFPN_Add2(nn.Module):
    """
    BiFPN åŒå‘ç‰¹å¾é‡‘å­—å¡”ç½‘ç»œ - 2è¾“å…¥åŠ æƒèåˆ
    ç”¨äºæ”¹è¿›çš„ç‰¹å¾èåˆï¼Œæå‡å°ç›®æ ‡æ£€æµ‹æ€§èƒ½
    
    Args:
        channels (int): è¾“å‡ºé€šé“æ•°ï¼ˆç”¨äºé€šé“å¯¹é½ï¼‰
        epsilon (float): é˜²æ­¢é™¤é›¶çš„å°å€¼ï¼Œé»˜è®¤ 1e-4
        
    Examples:
        >>> import torch
        >>> m = BiFPN_Add2(256)
        >>> x1 = torch.randn(1, 128, 32, 32)
        >>> x2 = torch.randn(1, 256, 32, 32)
        >>> y = m([x1, x2])
        >>> print(y.shape)  # torch.Size([1, 256, 32, 32])
    """
    
    def __init__(self, channels, epsilon=1e-4):
        super().__init__()
        self.epsilon = epsilon
        # å¯å­¦ä¹ çš„æƒé‡å‚æ•°ï¼ˆåˆå§‹åŒ–ä¸º1ï¼Œè¡¨ç¤ºåŒç­‰é‡è¦ï¼‰
        self.w = nn.Parameter(torch.ones(2) * 1.0)
        self.channels = channels
        # ç”¨äºå­˜å‚¨åŠ¨æ€åˆ›å»ºçš„é€šé“å¯¹é½å·ç§¯
        self.convs = nn.ModuleDict()
        
    def forward(self, x):
        """
        å‰å‘ä¼ æ’­ï¼šåŠ æƒèåˆä¸¤ä¸ªè¾“å…¥ç‰¹å¾ï¼ˆè‡ªåŠ¨å¤„ç†é€šé“å¯¹é½ï¼‰
        
        Args:
            x (list): åŒ…å«ä¸¤ä¸ªç‰¹å¾å¼ é‡çš„åˆ—è¡¨ï¼Œæ¯ä¸ªå½¢çŠ¶ä¸º (B, C, H, W)
            
        Returns:
            (torch.Tensor): èåˆåçš„ç‰¹å¾ï¼Œå½¢çŠ¶ä¸º (B, channels, H, W)
        """
        assert len(x) == 2, "BiFPN_Add2 requires exactly 2 inputs"
        x1, x2 = x[0], x[1]
        
        # é€šé“å¯¹é½ï¼šå¦‚æœé€šé“æ•°ä¸åŒï¼Œä½¿ç”¨ 1x1 å·ç§¯å¯¹é½åˆ°ç›®æ ‡é€šé“æ•°
        if x1.shape[1] != self.channels:
            key1 = f"conv1_{x1.shape[1]}"
            if key1 not in self.convs:
                self.convs[key1] = nn.Conv2d(x1.shape[1], self.channels, 1, bias=False).to(x1.device)
            x1 = self.convs[key1](x1)
        
        if x2.shape[1] != self.channels:
            key2 = f"conv2_{x2.shape[1]}"
            if key2 not in self.convs:
                self.convs[key2] = nn.Conv2d(x2.shape[1], self.channels, 1, bias=False).to(x2.device)
            x2 = self.convs[key2](x2)
        
        # å½’ä¸€åŒ–æƒé‡ï¼ˆä½¿ç”¨ softmax ç¡®ä¿æƒé‡å’Œä¸º1ï¼‰
        w = F.relu(self.w)
        w = w / (w.sum() + self.epsilon)
        
        # åŠ æƒèåˆ
        out = w[0] * x1 + w[1] * x2
        return out


class BiFPN_Add3(nn.Module):
    """
    BiFPN åŒå‘ç‰¹å¾é‡‘å­—å¡”ç½‘ç»œ - 3è¾“å…¥åŠ æƒèåˆ
    ç”¨äºæ”¹è¿›çš„ç‰¹å¾èåˆï¼Œæå‡å¤šå°ºåº¦ç‰¹å¾èåˆæ•ˆæœ
    
    Args:
        channels (int): è¾“å‡ºé€šé“æ•°ï¼ˆç”¨äºé€šé“å¯¹é½ï¼‰
        epsilon (float): é˜²æ­¢é™¤é›¶çš„å°å€¼ï¼Œé»˜è®¤ 1e-4
        
    Examples:
        >>> import torch
        >>> m = BiFPN_Add3(256)
        >>> x1 = torch.randn(1, 128, 32, 32)
        >>> x2 = torch.randn(1, 256, 32, 32)
        >>> x3 = torch.randn(1, 512, 32, 32)
        >>> y = m([x1, x2, x3])
        >>> print(y.shape)  # torch.Size([1, 256, 32, 32])
    """
    
    def __init__(self, channels, epsilon=1e-4):
        super().__init__()
        self.epsilon = epsilon
        # å¯å­¦ä¹ çš„æƒé‡å‚æ•°ï¼ˆåˆå§‹åŒ–ä¸º1ï¼Œè¡¨ç¤ºåŒç­‰é‡è¦ï¼‰
        self.w = nn.Parameter(torch.ones(3) * 1.0)
        self.channels = channels
        # ç”¨äºå­˜å‚¨åŠ¨æ€åˆ›å»ºçš„é€šé“å¯¹é½å·ç§¯
        self.convs = nn.ModuleDict()
        
    def forward(self, x):
        """
        å‰å‘ä¼ æ’­ï¼šåŠ æƒèåˆä¸‰ä¸ªè¾“å…¥ç‰¹å¾ï¼ˆè‡ªåŠ¨å¤„ç†é€šé“å¯¹é½ï¼‰
        
        Args:
            x (list): åŒ…å«ä¸‰ä¸ªç‰¹å¾å¼ é‡çš„åˆ—è¡¨ï¼Œæ¯ä¸ªå½¢çŠ¶ä¸º (B, C, H, W)
            
        Returns:
            (torch.Tensor): èåˆåçš„ç‰¹å¾ï¼Œå½¢çŠ¶ä¸º (B, channels, H, W)
        """
        assert len(x) == 3, "BiFPN_Add3 requires exactly 3 inputs"
        x1, x2, x3 = x[0], x[1], x[2]
        
        # é€šé“å¯¹é½ï¼šå¦‚æœé€šé“æ•°ä¸åŒï¼Œä½¿ç”¨ 1x1 å·ç§¯å¯¹é½åˆ°ç›®æ ‡é€šé“æ•°
        if x1.shape[1] != self.channels:
            key1 = f"conv1_{x1.shape[1]}"
            if key1 not in self.convs:
                self.convs[key1] = nn.Conv2d(x1.shape[1], self.channels, 1, bias=False).to(x1.device)
            x1 = self.convs[key1](x1)
        
        if x2.shape[1] != self.channels:
            key2 = f"conv2_{x2.shape[1]}"
            if key2 not in self.convs:
                self.convs[key2] = nn.Conv2d(x2.shape[1], self.channels, 1, bias=False).to(x2.device)
            x2 = self.convs[key2](x2)
        
        if x3.shape[1] != self.channels:
            key3 = f"conv3_{x3.shape[1]}"
            if key3 not in self.convs:
                self.convs[key3] = nn.Conv2d(x3.shape[1], self.channels, 1, bias=False).to(x3.device)
            x3 = self.convs[key3](x3)
        
        # å½’ä¸€åŒ–æƒé‡ï¼ˆä½¿ç”¨ softmax ç¡®ä¿æƒé‡å’Œä¸º1ï¼‰
        w = F.relu(self.w)
        w = w / (w.sum() + self.epsilon)
        
        # åŠ æƒèåˆ
        out = w[0] * x1 + w[1] * x2 + w[2] * x3
        return out


# ========================================
# Lightweight Modules for Edge Deployment
# ========================================

def autopad(k, p=None, d=1):
    """Pad to 'same' shape outputs."""
    if d > 1:
        k = d * (k - 1) + 1 if isinstance(k, int) else [d * (x - 1) + 1 for x in k]
    if p is None:
        p = k // 2 if isinstance(k, int) else [x // 2 for x in k]
    return p


class Conv(nn.Module):
    """Standard convolution with args(ch_in, ch_out, kernel, stride, padding, groups, dilation, activation)."""
    
    default_act = nn.SiLU()
    
    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, d=1, act=True):
        """Initialize Conv layer with given arguments including activation."""
        super().__init__()
        self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p, d), groups=g, dilation=d, bias=False)
        self.bn = nn.BatchNorm2d(c2)
        self.act = self.default_act if act is True else act if isinstance(act, nn.Module) else nn.Identity()
    
    def forward(self, x):
        """Apply convolution, batch normalization and activation to input tensor."""
        return self.act(self.bn(self.conv(x)))


class GSConv(nn.Module):
    """
    GSConv: Group Shuffle Convolution for Slim-Neck
    
    è½»é‡åŒ–å·ç§¯æ¨¡å—ï¼Œä½¿ç”¨æ·±åº¦å¯åˆ†ç¦»å·ç§¯ + é€šé“æ··æ´—é™ä½è®¡ç®—é‡ã€‚
    ä¸“ä¸ºè¾¹ç¼˜è®¾å¤‡ï¼ˆJetson Nanoï¼‰è®¾è®¡ã€‚
    
    Args:
        c1 (int): è¾“å…¥é€šé“æ•°
        c2 (int): è¾“å‡ºé€šé“æ•°
        k (int): å·ç§¯æ ¸å¤§å°
        s (int): æ­¥é•¿
        g (int): åˆ†ç»„æ•°
        act (bool): æ˜¯å¦ä½¿ç”¨æ¿€æ´»å‡½æ•°
    
    Reference:
        SlimNeck by GSConv: A Better Design Paradigm for Detector Architectures
    """
    
    def __init__(self, c1, c2, k=1, s=1, g=1, act=True):
        super().__init__()
        c_ = c2 // 2
        self.cv1 = Conv(c1, c_, k, s, g=g, act=act)
        self.cv2 = Conv(c_, c_, 5, 1, g=c_, act=act)
    
    def forward(self, x):
        """å‰å‘ä¼ æ’­ï¼ŒåŒ…å«é€šé“æ··æ´—"""
        x1 = self.cv1(x)
        x2 = self.cv2(x1)
        out = torch.cat((x1, x2), dim=1)
        
        # Channel shuffle
        b, c, h, w = out.shape
        out = out.view(b, 2, c // 2, h, w)
        out = out.transpose(1, 2).contiguous()
        out = out.view(b, c, h, w)
        return out


class GSBottleneck(nn.Module):
    """GSConv Bottleneck æ¨¡å—"""
    
    def __init__(self, c1, c2, k=3, s=1):
        super().__init__()
        c_ = c2 // 2
        self.cv1 = GSConv(c1, c_, k, s)
        self.cv2 = Conv(c_, c2, 1, 1, act=False)
    
    def forward(self, x):
        return self.cv2(self.cv1(x))


class VoVGSCSP(nn.Module):
    """
    VoV-GSCSP: è½»é‡åŒ– Neck æ¨¡å—
    
    ç»“åˆ VoV (One-Shot Aggregation) å’Œ GSConv çš„ CSP æ¨¡å—ã€‚
    ç”¨äºæ›¿ä»£ C2fï¼Œå¤§å¹…é™ä½ Neck çš„å‚æ•°é‡å’Œè®¡ç®—é‡ã€‚
    
    Args:
        c1 (int): è¾“å…¥é€šé“æ•°
        c2 (int): è¾“å‡ºé€šé“æ•°
        n (int): Bottleneck æ•°é‡
        shortcut (bool): æ˜¯å¦ä½¿ç”¨æ®‹å·®è¿æ¥
        g (int): åˆ†ç»„æ•°
        e (float): é€šé“æ‰©å±•æ¯”ä¾‹
    
    ç‰¹ç‚¹ï¼š
    - æ¯” C2f è½»é‡ 30-40%
    - ä¿æŒç›¸è¿‘çš„ç‰¹å¾æå–èƒ½åŠ›
    - é€‚åˆ TensorRT éƒ¨ç½²
    """
    
    def __init__(self, c1, c2, n=1, shortcut=False, g=1, e=0.5):
        super().__init__()
        c_ = int(c2 * e)
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = Conv(c1, c_, 1, 1)
        self.m = nn.ModuleList(GSBottleneck(c_, c_, k=3) for _ in range(n))
        self.cv3 = GSConv(c_ * (2 + n), c2, 1, 1)
    
    def forward(self, x):
        """VoV-style å‰å‘ä¼ æ’­"""
        x1 = self.cv1(x)
        x2 = self.cv2(x)
        feats = [x1, x2]
        
        for m in self.m:
            x2 = m(x2)
            feats.append(x2)
        
        return self.cv3(torch.cat(feats, dim=1))


class DySample(nn.Module):
    """
    DySample: åŠ¨æ€å†…å®¹æ„ŸçŸ¥ä¸Šé‡‡æ ·
    
    å­¦ä¹ æ€§ä¸Šé‡‡æ ·ç®—å­ï¼Œæ ¹æ®è¾“å…¥ç‰¹å¾åŠ¨æ€ç”Ÿæˆé‡‡æ ·ä½ç½®ï¼Œ
    æ¯”åŒçº¿æ€§æ’å€¼æ›´å¥½åœ°ä¿ç•™å°ç›®æ ‡çš„è¾¹ç¼˜ç»†èŠ‚ã€‚
    
    Args:
        in_channels (int): è¾“å…¥é€šé“æ•°
        scale (int): ä¸Šé‡‡æ ·å€æ•°
        style (str): å®ç°æ–¹å¼ ('lp' = å¯å­¦ä¹ å‚æ•°, 'pl' = PixelShuffle)
    
    Reference:
        DySample: Learning to Upsample by Learning to Sample (ICCV 2023)
    
    ä¼˜åŠ¿ï¼š
    - å†…å®¹æ„ŸçŸ¥ï¼šæ ¹æ®ç‰¹å¾è‡ªé€‚åº”è°ƒæ•´
    - è¾¹ç¼˜ä¿æŠ¤ï¼šæ›´å¥½çš„è¾¹ç•Œå®šä½
    - è½»é‡çº§ï¼šé€‚åˆè¾¹ç¼˜éƒ¨ç½²
    """
    
    def __init__(self, in_channels, scale=2, style='lp'):
        super().__init__()
        self.scale = scale
        self.style = style
        
        if style == 'lp':
            # ä½¿ç”¨ PixelShuffle å®ç°ï¼ˆTensorRT å‹å¥½ï¼‰
            self.upsample = nn.Sequential(
                Conv(in_channels, in_channels * (scale ** 2), 1, 1),
                nn.PixelShuffle(scale)
            )
        elif style == 'pl':
            # ä½¿ç”¨å¯å­¦ä¹ çš„ä¸Šé‡‡æ ·æ ¸
            self.upsample = nn.Sequential(
                Conv(in_channels, in_channels, 3, 1),
                nn.Upsample(scale_factor=scale, mode='bilinear', align_corners=False),
                Conv(in_channels, in_channels, 3, 1)
            )
        else:
            # æ ‡å‡†æ’å€¼ï¼ˆfallbackï¼‰
            self.upsample = nn.Upsample(scale_factor=scale, mode='bilinear', align_corners=False)
    
    def forward(self, x):
        """å‰å‘ä¼ æ’­"""
        return self.upsample(x)


# ============================================================================
# Edge Deployment Optimized Modules (V4)
# ============================================================================

class DySample_Simple(nn.Module):
    """
    DySample_Simple: TensorRT ä¼˜åŒ–ç‰ˆåŠ¨æ€ä¸Šé‡‡æ ·
    
    ç‰¹ç‚¹ï¼š
    1. ç§»é™¤ grid_sample æ“ä½œï¼ˆTensorRT ä¸å‹å¥½ï¼‰
    2. ä½¿ç”¨ PixelShuffle + åŠ¨æ€æƒé‡
    3. ä¿ç•™ 90%+ åŸç‰ˆç²¾åº¦
    4. æ¨ç†é€Ÿåº¦æå‡ 2-3x
    
    é€‚ç”¨äºï¼šJetson Nano, TensorRT, ONNX Runtime
    """
    
    def __init__(self, in_channels, scale=2, groups=4):
        super().__init__()
        self.scale = scale
        self.groups = min(groups, in_channels)
        
        # åŠ¨æ€æƒé‡ç”Ÿæˆ
        self.weight_gen = nn.Sequential(
            nn.Conv2d(in_channels, in_channels // 4, 1, bias=False),
            nn.BatchNorm2d(in_channels // 4),
            nn.SiLU(inplace=True),
            nn.Conv2d(in_channels // 4, self.groups * scale * scale, 1, bias=False),
            nn.BatchNorm2d(self.groups * scale * scale),
            nn.Sigmoid()
        )
        
        # PixelShuffle ä¸Šé‡‡æ ·
        self.upsample = nn.Sequential(
            nn.Conv2d(in_channels, in_channels * scale * scale, 1, bias=False),
            nn.BatchNorm2d(in_channels * scale * scale),
            nn.PixelShuffle(scale),
            nn.SiLU(inplace=True)
        )
    
    def forward(self, x):
        # ç”ŸæˆåŠ¨æ€æƒé‡
        weight = self.weight_gen(x)  # [B, groups*s*s, H, W]
        weight = F.interpolate(
            weight,
            size=(x.size(2) * self.scale, x.size(3) * self.scale),
            mode='bilinear',
            align_corners=False
        )
        
        # ä¸Šé‡‡æ ·
        out = self.upsample(x)  # [B, C, H*s, W*s]
        
        # åº”ç”¨åŠ¨æ€æƒé‡ï¼ˆå¹¿æ’­ï¼‰
        B, C, H, W = out.shape
        weight = weight.view(B, self.groups, -1, H, W).mean(dim=2, keepdim=True)
        weight = weight.expand(B, self.groups, C // self.groups, H, W)
        weight = weight.reshape(B, C, H, W)
        
        return out * weight


class GSBottleneck(nn.Module):
    """
    GSBottleneck: åŸºäº GSConv çš„ç“¶é¢ˆå—
    ç”¨äº VoVGSCSP å†…éƒ¨
    """
    
    def __init__(self, c1, c2, k=3, shortcut=True, g=1, e=0.5):
        super().__init__()
        c_ = int(c2 * e)
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = Conv(c_, c2, k, 1, g=g)
        self.add = shortcut and c1 == c2
    
    def forward(self, x):
        return x + self.cv2(self.cv1(x)) if self.add else self.cv2(self.cv1(x))
