# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license
"""
é¢å¤–çš„è‡ªå®šä¹‰æ¨¡å—ï¼šSPDConv å’Œ EMA
ç”¨äºå°ç›®æ ‡æ£€æµ‹çš„åˆ›æ–°ç®—å­
"""

import torch
import torch.nn as nn
import torch.nn.functional as F

__all__ = ("SPDConv", "EMA")


class SPDConv(nn.Module):
    """
    SPD-Conv: Space-to-Depth Convolution
    å®ç°ç©ºé—´è½¬æ·±åº¦çš„æ— æŸä¸‹é‡‡æ ·ï¼Œå°† 2x2 ç©ºé—´åŒºåŸŸè½¬æ¢ä¸º 4 å€æ·±åº¦é€šé“ã€‚
    
    é€‚ç”¨äºå°ç›®æ ‡æ£€æµ‹ï¼Œé¿å…ä¼ ç»Ÿä¸‹é‡‡æ ·å¯¼è‡´çš„ä¿¡æ¯ä¸¢å¤±ã€‚
    
    Args:
        in_channels (int): è¾“å…¥é€šé“æ•°
        out_channels (int): è¾“å‡ºé€šé“æ•°
        kernel_size (int): å·ç§¯æ ¸å¤§å°ï¼Œé»˜è®¤ 3
        stride (int): æ­¥é•¿ï¼Œé»˜è®¤ 1
        padding (int): å¡«å……ï¼Œé»˜è®¤ 1
        
    Examples:
        >>> import torch
        >>> m = SPDConv(64, 128)
        >>> x = torch.randn(1, 64, 64, 64)
        >>> y = m(x)
        >>> print(y.shape)  # torch.Size([1, 128, 32, 32])
    """
    
    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):
        super().__init__()
        self.conv = nn.Conv2d(
            in_channels * 4,  # SPD åé€šé“æ•°å˜ä¸º 4 å€
            out_channels,
            kernel_size=kernel_size,
            stride=stride,
            padding=padding,
            bias=False
        )
        self.bn = nn.BatchNorm2d(out_channels)
        self.act = nn.SiLU(inplace=True)
    
    def forward(self, x):
        """
        å‰å‘ä¼ æ’­ï¼šæ‰§è¡Œç©ºé—´åˆ°æ·±åº¦çš„è½¬æ¢ï¼Œç„¶åè¿›è¡Œå·ç§¯ã€‚
        
        Args:
            x (torch.Tensor): å½¢çŠ¶ä¸º (B, C, H, W) çš„è¾“å…¥å¼ é‡
            
        Returns:
            (torch.Tensor): å½¢çŠ¶ä¸º (B, out_channels, H//2, W//2) çš„è¾“å‡ºå¼ é‡
        """
        # Space-to-Depth: (B, C, H, W) -> (B, 4C, H/2, W/2)
        x = self.space_to_depth(x)
        x = self.conv(x)
        x = self.bn(x)
        x = self.act(x)
        return x
    
    @staticmethod
    def space_to_depth(x, block_size=2):
        """
        å°†ç©ºé—´ç»´åº¦è½¬æ¢ä¸ºæ·±åº¦ç»´åº¦ã€‚
        
        Args:
            x (torch.Tensor): è¾“å…¥å¼ é‡ï¼Œå½¢çŠ¶ (B, C, H, W)
            block_size (int): å—å¤§å°ï¼Œé»˜è®¤ 2
            
        Returns:
            (torch.Tensor): å½¢çŠ¶ä¸º (B, C*block_size^2, H//block_size, W//block_size)
        """
        B, C, H, W = x.shape
        # ç¡®ä¿å°ºå¯¸å¯è¢« block_size æ•´é™¤
        assert H % block_size == 0 and W % block_size == 0, \
            f"Height ({H}) and Width ({W}) must be divisible by block_size ({block_size})"
        
        # é‡å¡‘å¹¶é‡æ–°æ’åˆ—
        x = x.view(B, C, H // block_size, block_size, W // block_size, block_size)
        x = x.permute(0, 1, 3, 5, 2, 4).contiguous()
        x = x.view(B, C * (block_size ** 2), H // block_size, W // block_size)
        return x


class EMA(nn.Module):
    """
    EMA: Efficient Multi-Scale Attention
    å®ç°è½»é‡åŒ–çš„è·¨ç©ºé—´ç»´åº¦æ³¨æ„åŠ›æœºåˆ¶ï¼Œç”¨äºå¢å¼ºç‰¹å¾è¡¨è¾¾èƒ½åŠ›ã€‚
    
    é€šè¿‡åˆ†ç»„å·ç§¯å’Œå¤šå°ºåº¦æ± åŒ–å®ç°é«˜æ•ˆçš„æ³¨æ„åŠ›è®¡ç®—ã€‚
    
    Args:
        channels (int): è¾“å…¥/è¾“å‡ºé€šé“æ•°
        num_groups (int): åˆ†ç»„æ•°ï¼Œé»˜è®¤ 8
        spatial_kernel (int): ç©ºé—´æ³¨æ„åŠ›çš„å·ç§¯æ ¸å¤§å°ï¼Œé»˜è®¤ 7
        
    Examples:
        >>> import torch
        >>> m = EMA(256)
        >>> x = torch.randn(1, 256, 32, 32)
        >>> y = m(x)
        >>> print(y.shape)  # torch.Size([1, 256, 32, 32])
    """
    
    def __init__(self, channels, num_groups=8, spatial_kernel=7):
        super().__init__()
        self.channels = channels
        self.num_groups = num_groups
        assert channels % num_groups == 0, f"channels ({channels}) must be divisible by num_groups ({num_groups})"
        
        self.group_channels = channels // num_groups
        
        # 1x1 å·ç§¯ç”¨äºé€šé“æ³¨æ„åŠ›ï¼ˆä½¿ç”¨ GroupNorm é¿å…æ‰¹æ¬¡å¤§å°é™åˆ¶ï¼‰
        reduced_channels = max(channels // 4, 8)
        self.channel_attention = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Conv2d(channels, reduced_channels, 1, bias=False),
            nn.GroupNorm(num_groups=min(reduced_channels, 4), num_channels=reduced_channels),
            nn.SiLU(inplace=True),
            nn.Conv2d(reduced_channels, channels, 1, bias=False),
            nn.Sigmoid()
        )
        
        # åˆ†ç»„å·ç§¯ç”¨äºç©ºé—´æ³¨æ„åŠ›
        self.spatial_attention = nn.Sequential(
            nn.Conv2d(
                channels,
                channels,
                kernel_size=spatial_kernel,
                padding=spatial_kernel // 2,
                groups=num_groups,
                bias=False
            ),
            nn.GroupNorm(num_groups=num_groups, num_channels=channels),
            nn.Sigmoid()
        )
        
        # å¤šå°ºåº¦æ± åŒ–è·¯å¾„
        self.pool_sizes = [1, 3, 5]
        self.pool_convs = nn.ModuleList([
            nn.Sequential(
                nn.AvgPool2d(kernel_size=k, stride=1, padding=k // 2),
                nn.Conv2d(channels, channels, 1, bias=False),
                nn.GroupNorm(num_groups=num_groups, num_channels=channels)
            ) for k in self.pool_sizes
        ])
        
        # èåˆå±‚
        self.fusion = nn.Sequential(
            nn.Conv2d(channels * (len(self.pool_sizes) + 1), channels, 1, bias=False),
            nn.GroupNorm(num_groups=num_groups, num_channels=channels),
            nn.SiLU(inplace=True)
        )
    
    def forward(self, x):
        """
        å‰å‘ä¼ æ’­ï¼šè®¡ç®—å¤šå°ºåº¦æ³¨æ„åŠ›å¹¶åº”ç”¨åˆ°è¾“å…¥ç‰¹å¾ã€‚
        
        Args:
            x (torch.Tensor): å½¢çŠ¶ä¸º (B, C, H, W) çš„è¾“å…¥å¼ é‡
            
        Returns:
            (torch.Tensor): å½¢çŠ¶ä¸º (B, C, H, W) çš„è¾“å‡ºå¼ é‡
        """
        B, C, H, W = x.shape
        identity = x
        
        # é€šé“æ³¨æ„åŠ›
        ca = self.channel_attention(x)
        x_ca = x * ca
        
        # ç©ºé—´æ³¨æ„åŠ›
        sa = self.spatial_attention(x)
        x_sa = x * sa
        
        # å¤šå°ºåº¦æ± åŒ–
        pool_feats = [x_ca]
        for pool_conv in self.pool_convs:
            pool_feats.append(pool_conv(x_sa))
        
        # èåˆæ‰€æœ‰å°ºåº¦
        x_fused = torch.cat(pool_feats, dim=1)
        x_fused = self.fusion(x_fused)
        
        # æ®‹å·®è¿æ¥
        out = x_fused + identity
        return out
